{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "096fcff2-6dd2-42e3-9325-0566ecc1d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import logical_and as land\n",
    "from numpy import logical_or as lor\n",
    "from numpy import invert as lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90dc0a2c-c2f5-4096-b367-ad491ff2cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theta(mu, cov, rho):\n",
    "    '''\n",
    "    Returns explicit threshold theta for a given percentage rho of anomalies in \n",
    "    data distributed as a Gaussian with mean mu and covariance matrix cov. \n",
    "    \n",
    "    Parameters\n",
    "        mu    mean of Gaussian distribution\n",
    "        cov   covariance matrix of Gaussian distribution\n",
    "        rho   percentage of anomalies, which must be between 0 and 100 inclusive\n",
    "    '''\n",
    "    # generate random variables (data)\n",
    "    X = multivariate_normal.rvs(mean=mu, cov=cov, size=5000000)\n",
    "    # center data (normalize) (for x_i - mu)\n",
    "    Z = X - mu\n",
    "    # calculate the mahalanobis distance\n",
    "    # d2M (xi, ˆμ) = (xi − ˆμ)T ˆΣ−1(xi − ˆμ)\n",
    "    d = np.sqrt(np.sum(Z.dot(inv(cov)) * Z, axis=1))\n",
    "    # tetha = \n",
    "    return np.percentile(d, 100-rho) \n",
    "\n",
    "# get_theta([0, 0], [[1, 0], [0, 1]], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402a9923-6d8c-4b78-9628-8b5ca9848b0a",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "1. Sample a data set D of size n from N (x; μ, Σ). Fix a percentage ρ.\n",
    "2. Use the function get_theta(mu, cov, rho) provided by the notebook to\n",
    "obtain an explicit threshold θ given the percentage ρ. Note that θ is part\n",
    "of the ground-truth and therefore considered as unknown.\n",
    "3. Determine the true anomalies of D. For this, use the explicit threshold θ\n",
    "together with the Mahalanobis distance d∗\n",
    "M defined by the true μ and Σ.\n",
    "4. Use the data D to estimate μ and Σ. Construct the Mahalanobis distance\n",
    "dM defined by the estimates ˆμ and ˆΣ.\n",
    "5. Predict the anomalies of D using the Mahalanobis distance dM and Eu-\n",
    "clidean distance dE . Anomalies are the ρ percent points xi ∈ D farthest\n",
    "from ˆμ (do not use θ). Assess precision and recall of both detectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bacb0cf2-3dc4-4581-9214-19549490b346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate the whole assignment\n",
    "def evaluate( mu_T=np.array([0, 0]), covariance=.9, rho=3, size=2000):\n",
    "    \n",
    "     # fixate groundtruth mean and covariance matrix for the bivariate gaussian distribution\n",
    "    # '_T' nominator stands for groundtruth variable\n",
    "    # '_E' nominator stands for estimated variable\n",
    "    sigma_T = np.array([[1, covariance], [covariance, 1]])  # covariance matrix\n",
    "    \n",
    "    # 0. generate dataset (RandomVariableS)\n",
    "    D = multivariate_normal.rvs(mean=mu_T, cov=sigma_T, size=size)\n",
    "    \n",
    "     # 2. use get_theta to get the 'groundtruth' explicit treshold theta\n",
    "    theta = get_theta(mu_T, sigma_T, rho)\n",
    "    \n",
    "    # 3. determine subset of true anomalies of dataset D\n",
    "    # start by calculating the mahalanobis distance of each point from the mean\n",
    "    Z_T = D - mu_T\n",
    "    d_m_T = np.sqrt(np.sum(Z_T.dot(inv(sigma_T)) * Z_T, axis=1))\n",
    "    \n",
    "    # filter out values (indices) over the groundtruth threshold theta (True / False array)\n",
    "    I_T = d_m_T > theta  # indices of true anomalies with mahalanobis distance\n",
    "    \n",
    "    # 4. Use the data D to estimate mu and sigma\n",
    "    mu_E = D.mean(axis=0)\n",
    "    sigma_E = np.cov(D.T) \n",
    "    \n",
    "    # Construct the Mahalanobis distance d_m_E defined by the estimates mu_E and sigma_E\n",
    "    Z_E = D - mu_E\n",
    "    d_m_E = np.sqrt(np.sum(Z_E.dot(inv(sigma_E)) * Z_E, axis=1))\n",
    "    \n",
    "    # construct euklidian distance d_e_E in the same manner (with mu_E and sigma_E)\n",
    "    d_e_E = np.sqrt(np.sum(Z_E ** 2, axis=1)) \n",
    "    \n",
    "    # 5. predict anomalies with estimated eucilidian (d_e_E) and mahalanobis distance (d_m_E)\n",
    "    # create list of indices (True / False array) (on axis 0 of dataset)\n",
    "    # estimated thresholds (eta) are rho percent points with the farthest distance from mu_E\n",
    "    eta_m = np.percentile(d_m_E, 100-rho)\n",
    "    eta_e = np.percentile(d_e_E, 100-rho) \n",
    "\n",
    "    I_m_E = d_m_E > eta_m\n",
    "    I_e_E = d_e_E > eta_e \n",
    "    \n",
    "    # Comparison:\n",
    "    # Assess precision and recall of both detectors. (5)\n",
    "    # calculate tp, fp and fn for euklidian distance and for mahalanobis distance\n",
    "\n",
    "    # np.logical_and(I_m_T, I_m_E) [here: land] creates a logical AND mask over the two boolean arrays etc.\n",
    "    # (I_m_T * I_m_E)\n",
    "    tp_m = land(I_T, I_m_E).sum()\n",
    "    tp_e = land(I_T, I_e_E).sum()\n",
    "\n",
    "    fp_m = land(lin(I_T), I_m_E).sum()\n",
    "    fp_e = land(lin(I_T), I_e_E).sum()\n",
    "\n",
    "    fn_m = land(I_T, lin(I_m_E)).sum()\n",
    "    fn_e = land(I_T, lin(I_e_E)).sum()\n",
    "\n",
    "    # precisions and recalls mahalanobis (m) and euklidian (e) distance\n",
    "    precision_m = tp_m / (tp_m + fp_m) \n",
    "    recall_m = tp_m / (tp_m + fn_m)\n",
    "\n",
    "    precision_e = tp_e / (tp_e + fp_e)\n",
    "    recall_e = tp_e / (tp_e + fn_e)\n",
    "\n",
    "    print(f'precision euklidian : {precision_e}')\n",
    "    print(f'precision mahalanobis : {precision_m}')\n",
    "    print(f'recall euklidian : {recall_e}')\n",
    "    print(f'recall mahalanobis : {recall_m}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2237763b-eb8a-4d21-a6cb-43b754a756d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision euklidian : 0.5666666666666667\n",
      "precision mahalanobis : 1.0\n",
      "recall euklidian : 0.5074626865671642\n",
      "recall mahalanobis : 0.8955223880597015\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f781b184-55e6-40dc-b769-db519df62cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538059f0-3f81-4248-9b72-0f1432601063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
